\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{float}
\usepackage{fontawesome}
\usepackage{multicol}
\usepackage{listings}
\usepackage{array}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{bookmark}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}

% Beamer theme settings
\usetheme{Madrid}
\usecolortheme{default}

\title{URL Coursework 2}
\subtitle{StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks~\cite{stackgan++}}
\author{Bruno Sánchez Gómez}
\date{\today}

\setbeamertemplate{footline}{%
    \leavevmode%
    \hbox{%
        \begin{beamercolorbox}[wd=0.2\paperwidth,ht=2.5ex,dp=1.125ex,center]{author in head/foot}%
            \hspace*{1mm}Bruno Sánchez Gómez
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=0.7\paperwidth,ht=2.5ex,dp=1.125ex,center]{title in head/foot}%
            \insertshortsubtitle
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=0.1\paperwidth,ht=2.5ex,dp=1.125ex,center]{date in head/foot}%
            \hspace*{-1mm}\insertframenumber{} / \inserttotalframenumber
        \end{beamercolorbox}%
    }%
    \vskip0pt%
}

% Define a command for placeholder images for clarity
\newcommand{\paperfigure}[3][width=\textwidth]{%
    \begin{figure}%
        \centering%
        \includegraphics[#1]{figures/#2.png}%
        \caption{#3 (Source:~\cite{stackgan++})}%
    \end{figure}%
}


\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\section{Introduction}
\begin{frame}{Table of Contents}
    \tableofcontents
\end{frame}

\begin{frame}{Introduction}
    \centering
    \begin{minipage}{0.9\textwidth}
        \begin{block}{Area of Research of the Paper}
            \textbf{Generative Adversarial Networks} (GANs) for Image Generation
        \end{block}
    \end{minipage}
    \vspace{1em}
    \begin{itemize}
        \item \textbf{StackGAN++} focuses on:
        \begin{itemize}
            \item High-resolution images ($256 \times 256$ pixels)
            \item Two tasks:
            \begin{itemize}
                \item \textit{Unconditional Image Generation}
                \item \textit{Text-to-Image Synthesis} (Conditional Image Generation)
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \pause
    \begin{itemize}
        \item \textbf{Limitations of prior work with GANs:}
        \begin{itemize}
            \item Training instability
            \item Mode collapse
            \item Difficulty in generating high-resolution images
        \end{itemize}
    \end{itemize}
\end{frame}

% GAN Training Instability:
%   - Sensitive to hyperparameters
%   - Can suffer from non-convergence

% Mode Collapse:
%   - Limited variety of generated samples
%   - Fail to capture full diversity of the training data

% Limited to low-resolution images:
%   - Training GANs for high-resolution images is especially difficult and unstable.
%   - High-dimensional image spaces make it hard for model and data distributions to overlap, leading to poor gradients.

\begin{frame}{Contributions by StackGAN++}
    \begin{itemize}
        \item \textbf{Conditioning Augmentation (CA):} Improve sample diversity by augmenting the image-text pairs.
        \vspace{1em}
        \item \textbf{StackGAN:} Two GAN frameworks for conditional and unconditional image synthesis with high resolution ($256 \times 256$):
        \vspace{0.5em}
        \begin{itemize}
            \item \textbf{StackGAN-v1:} Two-stage GAN
            \vspace{0.25em}
            \item \textbf{StackGAN-v2:} Multi-stage GAN with a tree-like structure
        \end{itemize}
    \end{itemize}
\end{frame}

\section{StackGAN++ Methodology}
\begin{frame}{Table of Contents}
    \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Conditioning Augmentation (CA)}
    \centering
    \begin{minipage}{0.8\textwidth}
        \begin{block}{Core Idea}
            \centering
            Augment the text conditioning to improve sample diversity and stabilize GAN training
        \end{block}
    \end{minipage}
    \vspace{1em}
    \begin{itemize}
        \item The latent space for text embeddings, $\phi_t$, is high-dimensional
        \item Limited data causes discontinuity in the latent data manifold
        \item CA samples a new embedding $\hat{c}$ from a Gaussian distribution:
        \[
        \hat{c} = N(\mu_\theta(\phi_t), \Sigma_\theta(\phi_t))
        \]
        \item To further enforce smoothness over the conditioning manifold and avoid overﬁtting, a regularization term is added to the loss:
        \[
        \mathcal{L}_{\text{KL}} = D_{KL}\big(N(\mu_\theta(\phi_t), \Sigma_\theta(\phi_t))\, ||\, N(0, I)\big)
        \]
    \end{itemize}  
\end{frame}

\begin{frame}{StackGAN-v1}
    \centering
    \begin{minipage}{0.8\textwidth}
        \begin{block}{Core Idea}
            \centering
            Decompose text-to-image generation into a sketch-refinement process
        \end{block}
    \end{minipage}
    \paperfigure[width=0.9\textwidth]{stackgan_v1}{StackGAN-v1 Architecture}
\end{frame}

% The input to the second stage is a 64x64 image from the first stage, along with the text embedding (conditioning), instead of noise

\begin{frame}{StackGAN-v2}
    \centering
    \begin{minipage}{0.8\textwidth}
        \begin{block}{Core Idea}
            \centering
            A more general, end-to-end multi-stage framework with a tree-like structure
        \end{block}
    \end{minipage}
    \paperfigure[width=0.9\textwidth]{stackgan_v2}{StackGAN-v2 Architecture and JCU Discriminators}
\end{frame}

% JCU (Joint Conditional/Unconditional) Discriminator: It predicts whether an image is real or fake, and whether the image matches the text condition or not
% Generators are jointly trained to approximate image distributions at multiple scales, instead of being split into two stages
% Color-Consistency Regularization: Encourages images generated at different scales from the same input to have similar color statistics (mean, covariance). Crucial for unconditional tasks

\section{Results}
\begin{frame}{Table of Contents}
    \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Experimental Setup}
    \centering
    \begin{tabular}{|p{0.15\textwidth}|p{0.23\textwidth}|p{0.22\textwidth}|}
        \hline
        & \textbf{Unconditional} & \textbf{Conditional} \\
        \hline
        \multirow{4}{0.15\textwidth}{\textbf{Datasets}} 
            & \multirow{4}{0.25\textwidth}{LSUN \newline ImageNet}
            & \multirow{4}{0.25\textwidth}{CUB-200-2011 \newline Oxford-102 \newline MS COCO} \\
        & & \\
        & & \\
        & & \\
        \hline
        \multirow{6}{0.15\textwidth}{\textbf{Competing Methods}} 
            & \multirow{6}{0.25\textwidth}{DCGAN \newline WGAN \newline EBGAN-PT \newline LSGAN \newline WGAN-GP}
            & \multirow{6}{0.25\textwidth}{GAN-INT-CLS \newline GAWWN} \\
        & & \\
        & & \\
        & & \\
        & & \\
        & & \\
        \hline
    \end{tabular}
    \vspace{1em}

    % Evaluation Metrics Table
    \centering
    \begin{tabular}{|p{0.15\textwidth}|p{0.5\textwidth}|}
        \hline
        \multirow{3}{0.15\textwidth}{\textbf{Evaluation Metrics}} & \textit{Inception Score (IS)}             $\uparrow$ \\\cline{2-2}
                                                                  & \textit{Fréchet Inception Distance (FID)} $\downarrow$ \\\cline{2-2}
                                                                  & \textit{Human Rank (HR)}                  $\downarrow$ \\
        \hline
    \end{tabular}
\end{frame}

% Inception Score (IS): Measures image quality and diversity.
% Fréchet Inception Distance (FID): Measures similarity between generated and real image distributions.
% Human Rank (HR): User studies:
    % 30 human users (who are not authors of the paper) are given the same text descriptions. 
    % For each text description, they are shown the images generated by the different methods.
    % The users are asked to rank the results (the generated images) from the different methods.

\begin{frame}{Quantitative Results}
    \paperfigure[width=\textwidth]{quantitative_results}{Tables of quantitative results}
\end{frame}

\begin{frame}{Qualitative Results: Unconditional Image Generation}
    \paperfigure[width=\textwidth]{qualitative_results_unconditional}{Comparison of generated samples from LSUN Bedroom}
\end{frame}

\begin{frame}{Qualitative Results: Text-to-Image}
    \paperfigure[width=0.9\textwidth]{qualitative_results_conditional}{Comparison of generated samples with text descriptions from CUB}
\end{frame}

\begin{frame}{Limitations: StackGAN-v1 Mode Collapse}
    \paperfigure[width=\textwidth]{mode_collapse}{StackGAN-v1 suffers from mode collapse}
\end{frame}

\begin{frame}{Limitations: Failure Cases}
    \paperfigure[width=\textwidth]{failure_cases}{Failure cases of both StackGAN-v1 and StackGAN-v2}
\end{frame}

\begin{frame}{Ablation Studies}
    \paperfigure[width=0.5\textwidth]{ablation_v1}{Component analysis of StackGAN-v1}
    \paperfigure[width=0.9\textwidth]{ablation_v2}{Component analysis of StackGAN-v2}
\end{frame}

% Both on the CUB dataset

\section{Conclusions}
\begin{frame}{Table of Contents}
    \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Conclusions}
    \begin{itemize}
        \item \textbf{Stacked/Multi-Stage GANs} are highly effective
        \item \textbf{Conditioning Augmentation} significantly improves sample diversity and training stability
        \item \textbf{StackGAN-v1} succeeds in generating high-resolution images with photo-realistic details
        \item \textbf{StackGAN-v2} improves robustness by jointly approximating:
        \begin{enumerate}
            \item Multi-scale image distributions
            \item Conditional and unconditional image distributions
        \end{enumerate}
        \item \textbf{Quantitative and Qualitative Results} demonstrate superior performance over prior SOTA methods
        \item \textbf{Ablation Studies} validate the effectiveness of each component
    \end{itemize}
\end{frame}

\begin{frame}{Personal Comments}
    
    \setbeamercolor{block title}{bg=red!20, fg=black}
    \setbeamercolor{block body}{bg=red!5, fg=black}
    \begin{block}{\textbf{Cons}}
        \begin{itemize}
            \item \textbf{JCU Discriminators} could have also been used in \textbf{StackGAN-v1}
            \item The authors \textbf{did not include StackGAN-v2 in the quantitative analysis} against SOTA methods
            \item The improvement in \textbf{image quality} from the qualitative results is \textbf{not very significant}
        \end{itemize}
    \end{block}
    
    \setbeamercolor{block title}{bg=green!20, fg=black}
    \setbeamercolor{block body}{bg=green!5, fg=black}
    \begin{block}{\textbf{Pros}}
        \begin{itemize}
            \item It mantains the \textbf{same level of quality} at \textbf{higher resolutions}
            \item The idea of progressive refinement as a way to tackle high-resolution image synthesis is \textbf{well-motivated}, \textbf{intuitive}, and \textbf{empirically validated}
        \end{itemize}
    \end{block}
    \begin{itemize}
        \item The paper was published in 2018, and since then, there have been \textbf{many advancements} in the field of GANs (e.g. \textit{StyleGAN}~\cite{stylegan})
    \end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{References}
    \nocite{*} % To include all references from the .bib file, even if not explicitly cited in text (though StackGAN++ is cited)
    \bibliographystyle{unsrt} 
    \bibliography{references}
\end{frame}

\end{document}